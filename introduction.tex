\section{Introduction}
\label{sec:introduction}

Verification --- by which we mean the general practice of checking the correctness of a computer-based system before it is put into use --- was first developed to
check the correctness of hardware, and is now increasingly used in the software development process. While networks have been around for many decades and are now an essential piece of our computational infrastructure, only recently has verification been applied to ensure their correctness.\footnote{There has been much work on verifying network protocols and their implementations, but until recently almost none on verifying a given network configuration.} As a result, there is now a growing literature on systems that can verify that the current or proposed network configuration (as represented by router forwarding tables) obey various important invariants (such as no routing loops or deadends).
These systems --- which allow network operators to verify that their networks will operate correctly, in terms of some well-defined invariants -- represent a valuable, and long overdue, step forward for networking, which for too long was satisfied with not only {\em best-effort} service but also {\em best-guess} configuration. In this position paper we critically review this recent progress, propose some next steps towards a more complete form of network verification, and end with a discussion of the formal questions posed to this community by the network verification agenda.

In the rest of this section, we provide some necessary background on networks and the current verification techniques. The application of verification to networking coincided with the rise of Software-Defined Networking (SDN). While not essential for the use of verification in networks, SDN provides a useful platform on which to deploy these tools so we discuss verification within the SDN context. Networks are comprised of two planes: the {\em data plane} which decides how packets are handled locally by each router (based on the local forwarding state and other information, such as state generated by previous packets), and the {\em control plane} which is a global process that computes and updates the local forwarding state in each router. In legacy networks, both planes are implemented in routers (with the data plane being the forwarding code or datapath, and the control plane being the global routing algorithm), but in SDN there is a clean separation between the two planes. The SDN control plane is logically centralized, and implemented in a few servers (called controllers) that compute and then install the necessary forwarding state. SDN-controlled routers only implement the data plane, executing a very simple datapath (OpenFlow \cite{openflow}) in which the routing state is a set of
$\langle \textit{match}, \textit{action} \rangle$ flow entries: all packets with headers matching the $match$ entry are subject to the specified $action$ which is often either to forward out a specific port (perhaps with a slightly modified header) or to drop the packet.
One can think of this network state as the {\em configuration} of a router.

The first wave of verification tools \cite{anteater,khurshid2012veriflow,oldhsa,kazemian2013real} analyzed the global behavior of a network made up of switches obeying this simple forwarding model. As a packet travels through the network, its next-hop is dictated by the routing state in the current router; thus, this network-wide behavior can be thought of as the composition of the routing state in each router. These early verification tools would take a snapshot of network state (either that which is already in the network, or that which the control is poised to insert into the network) and then verify whether some basic invariants held. These invariants (which are specified by the network operator) are typically quite simple and few in number: reachability (e.g., packets from host A can reach host B), isolation (e.g., packets from host A cannot reach host B), loop-freedom (no packet enters into an infinite loop), and no dead-ends (no packet arrives at a router which cannot forward it to another router or to the end-destination). Subsequent network verification tools (e.g., \cite{guha2013machine,anderson2014netkat,flowlog}) make the same assumptions about the datapath, but generalize along various other dimensions.

All of these tools leverage the fact that the simple forwarding model renders the datapath {\em immutable}; by this we mean that the forwarding behavior does not change until the control plane explicitly alters the routing state (which happens on relatively slow time scales). Thus, one can verify the invariants before each control-plane-initiated change and know that the network will always enforce the operator-specified invariants.

While the notion of an immutable datapath supported by an assemblage of routers makes verification tractable, it does not reflect reality. Modern enterprise networks are comprised of roughly $\nicefrac{2}{3}$ routers\footnote{In this paper we do not distinguish between routers and switches, since they obey similar forwarding models.} and $\nicefrac{1}{3}$ {\em middleboxes}~\cite{sherry2012making}.  Middleboxes -- such as Firewalls, WAN Optimizers, Transcoders, Proxies, Load Balancers, Intrusion Detection Systems (IDS) and the like --  are the most common way to insert new functionality in the network datapath, and are commonly used to improve network performance and security.\footnote{We should note that the NFV movement is moving middleboxes out of separate physical machines and into VMs that can be hosted on a cluster of servers; however, nothing in the move from physical to virtual middleboxes changes our story.} 

Just as the configuration of router is the state it uses to make forwarding decisions, the configuration of a middlebox is its set of policies (e.g., drop all Skype packets). The configuration of a network is the configurations of all of its routers, all of its middleboxes, and the topology of the physical network connecting these elements. The goal of verification is to ensure that a given network configuration supports a given invariant.

While useful, middleboxes are a common source of errors in the network~\cite{potharaju2013demystifying}, with middlebox misconfigurations account for over $40\%$ of all major
incidents in networks. Thus, one cannot ignore middleboxes when verifying network configurations.

However, middleboxes do not adhere to the simple forwarding model in routers. Many middleboxes have a {\em mutable} datapath, in which the handling of a packet depends not just on immutable forwarding state, but also on the sequence of previously encountered packets (e.g., a firewall packets from a flow into a network, but only if it has previously seen an outgoing packet from that flow).  This dependence on the packet histories renders the datapath quite mutable (changing on packet timescales). This prevents the use of current verification techniques, because the control over packet behaviors is no longer centralized in the control plane but is, in the most general case, dependent on the packet histories seen by every middlebox.


Thus, we must find a way to verify network behavior in the presence of middleboxes, which means finding verification techniques that can deal with mutable datapaths. Since the forwarding behavior of a mutable datapath can depend arbitrarily on the past packet history, middleboxes render the network Turing-complete. Thus, any verification technique that copes with middleboxes will look much more like general program verification than the current generation of network verification tools. There are two main technical challenges to building the next generation of network verification tools:
\begin{itemize}
\item How do we model these mutable datapaths so that the complexity of verification is tractable?
\item How can we feasibly analyze a network made up of these mutable datapaths?
\end{itemize}
We address these two challenges in the following sections, and then discuss  how to formalize this approach and end by describing a set of open questions.